
# Speech Emotion Recognition using LSTM (Zidio_Project_2)

## Overview

This project implements a Speech Emotion Recognition (SER) system using LSTM neural networks. The system analyzes audio recordings to classify emotional states such as anger, joy, sadness, and more. The model is trained on the Toronto Emotional Speech Set (TESS) dataset.

## Colab Notebook

- `Speech Emotion Recognition using LSTM(Zidio_Project_2).ipynb`: Colab notebook containing the implementation of the SER system using LSTM. You can open and run this notebook in Google Colab.

## Usage

1. **Open in Colab**:
   - Click on the `Speech Emotion Recognition using LSTM(Zidio_Project_2).ipynb` file above to open it directly in Google Colab.

2. **Run the notebook**:
   - Follow the instructions within each cell of the notebook to execute the code for training the LSTM model and evaluating its performance.

3. **Adjust hyperparameters**:
   - Modify parameters within the notebook to optimize model performance or experiment with different settings.

## Results

The LSTM model achieves an accuracy of over 80% on the validation set, demonstrating effective recognition of speech emotions.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
